name: Daily Tech Digest Pipeline

on:
  schedule:
    # Run Monday-Friday at 6 AM UTC (weekdays only)
    - cron: '0 6 * * 1-5'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      mode:
        description: 'Processing mode'
        required: false
        default: 'normal'
        type: choice
        options:
        - normal
        - test-run
        - friday-weekly
        - monday-catchup
      debug:
        description: 'Enable debug output'
        required: false
        default: false
        type: boolean

permissions:
  contents: write  # Allow the workflow to push changes
  packages: read   # Allow reading packages if needed

jobs:
  daily-podcast-digest:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for proper git operations
        token: ${{ secrets.GITHUB_TOKEN }}
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Cache Python dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-v1
        restore-keys: |
          ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-
          ${{ runner.os }}-pip-
          
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        # sqlite3 is built into Python, no need to install via pip
        
    - name: Cache system dependencies  
      uses: awalsh128/cache-apt-pkgs-action@latest
      with:
        packages: ffmpeg sqlite3
        version: 1.0
        
    # Note: Removed database caching - databases should use current repo state, not cached versions
    # This allows database changes committed to the repo to be properly used by the workflow
          
    - name: Show workflow configuration  
      run: |
        echo "üéØ Workflow Mode: ${{ github.event.inputs.mode || 'normal (scheduled)' }}"
        echo "üêõ Debug Mode: ${{ github.event.inputs.debug || 'false' }}"
        echo "‚ö° Trigger: ${{ github.event_name }}"
        echo "üìÖ Current day: $(date -u +%A)"
        
        # Determine workflow behavior based on day and mode
        WORKFLOW_MODE="${{ github.event.inputs.mode }}"
        CURRENT_DAY=$(date -u +%u)  # 1=Monday, 5=Friday
        
        if [ "$WORKFLOW_MODE" == "test-run" ]; then
          echo "üß™ TEST MODE: No commits, pushes, or releases will be made"
        elif [ "$WORKFLOW_MODE" == "friday-weekly" ] || [ "$CURRENT_DAY" == "5" ]; then
          echo "üóìÔ∏è  FRIDAY MODE: Daily + Weekly digest generation"
          echo "FRIDAY_WEEKLY=true" >> $GITHUB_ENV
        elif [ "$WORKFLOW_MODE" == "monday-catchup" ] || [ "$CURRENT_DAY" == "1" ]; then
          echo "üìÖ MONDAY MODE: Catch-up processing since Friday 06:00"
          echo "MONDAY_CATCHUP=true" >> $GITHUB_ENV
        else
          echo "üìÜ REGULAR WEEKDAY: Standard daily processing"
        fi
        
    - name: Set up environment variables
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Validate required API keys are present before setting
        if [ -z "$ANTHROPIC_API_KEY" ]; then
          echo "‚ùå ANTHROPIC_API_KEY secret is not set or empty"
          exit 1
        fi
        if [ -n "$ANTHROPIC_API_KEY" ]; then
          echo "‚úÖ ANTHROPIC_API_KEY is set (length: ${#ANTHROPIC_API_KEY})"
        fi
        
        if [ -n "$OPENAI_API_KEY" ]; then
          echo "‚úÖ OPENAI_API_KEY is set (length: ${#OPENAI_API_KEY})"
        else
          echo "‚ö†Ô∏è OPENAI_API_KEY secret is not set - topic scoring will be skipped"
        fi
        
        echo "ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY" >> $GITHUB_ENV
        echo "OPENAI_API_KEY=$OPENAI_API_KEY" >> $GITHUB_ENV
        echo "ELEVENLABS_API_KEY=$ELEVENLABS_API_KEY" >> $GITHUB_ENV
        echo "GITHUB_TOKEN=$GITHUB_TOKEN" >> $GITHUB_ENV
        
    - name: Run Multi-Topic Podcast Pipeline (GitHub Actions mode)
      run: |
        if [ "${{ github.event.inputs.debug }}" == "true" ]; then
          echo "üêõ Debug mode enabled"
          export DEBUG=1
        fi
        
        if [ "${{ github.event.inputs.mode }}" == "test-run" ]; then
          echo "üß™ Test run mode - will not deploy or update feeds"
          python3 daily_podcast_pipeline.py --rss-only --test
        elif [ "$FRIDAY_WEEKLY" == "true" ]; then
          echo "üóìÔ∏è  Friday mode - generating daily + weekly digests"
          python3 daily_podcast_pipeline.py --rss-only --weekly
        elif [ "$MONDAY_CATCHUP" == "true" ]; then
          echo "üìÖ Monday catch-up mode - processing since Friday"
          python3 daily_podcast_pipeline.py --rss-only --catchup
        else
          echo "üöÄ Regular weekday processing mode"
          python3 daily_podcast_pipeline.py --rss-only
        fi
        
    - name: Debug TTS Generation (CRITICAL)
      if: always()
      run: |
        echo "=========================================="
        echo "üéµ TTS GENERATION DEBUGGING (CRITICAL)"
        echo "=========================================="
        
        echo "=== Environment Variables ==="
        echo "ELEVENLABS_API_KEY length: ${#ELEVENLABS_API_KEY}"
        echo "ANTHROPIC_API_KEY length: ${#ANTHROPIC_API_KEY}"
        if [ -z "$ELEVENLABS_API_KEY" ]; then
          echo "‚ùå ELEVENLABS_API_KEY is EMPTY or UNSET"
        else
          echo "‚úÖ ELEVENLABS_API_KEY is set"
        fi
        
        echo "=== Daily Digests Directory ==="
        ls -la daily_digests/ || echo "‚ùå No daily_digests/ directory"
        
        echo "=== Topic-Specific Digest Files ==="
        find daily_digests/ -name "*_digest_*.md" -exec echo "üìÑ Found digest: {}" \; 2>/dev/null || echo "‚ùå No topic digest files found"
        
        echo "=== All TTS Text Files ==="
        find daily_digests/ -name "*_digest_tts_*.txt" -exec echo "üìù Found TTS text: {}" \; 2>/dev/null || echo "‚ö†Ô∏è No TTS text files found"
        
        echo "=== Topic-Specific Audio Files ==="
        find daily_digests/ -name "*_digest_*.mp3" -exec echo "üéµ Found audio: {}" \; 2>/dev/null || echo "‚ùå No audio files found"
        
        echo "=== All JSON Metadata Files ==="
        find daily_digests/ -name "*_digest_*.json" -exec echo "üìä Found metadata: {}" \; 2>/dev/null || echo "‚ö†Ô∏è No metadata files found"
        
        echo "=== Manual Multi-Topic TTS Generation Test ==="
        echo "üß™ Testing multi-topic TTS script directly..."
        python3 multi_topic_tts_generator.py 2>&1 || echo "‚ùå Multi-topic TTS script failed"
        
        echo "=== Post-TTS Directory Check ==="
        ls -la daily_digests/ | grep -E "\.(mp3|json|txt|md)$" || echo "‚ùå No files after TTS test"
        
        echo "=== TTS Script Output Analysis ==="
        if [ -f daily_digests/claude_digest_full_*.txt ]; then
          echo "‚úÖ TTS full script found"
        else
          echo "‚ùå TTS full script missing"
        fi
        
        if [ -f daily_digests/claude_digest_tts_*.txt ]; then
          echo "‚úÖ TTS optimized script found"  
        else
          echo "‚ùå TTS optimized script missing"
        fi
        
        echo "=== Topic Digest Timestamp Matching ==="
        LATEST_DIGEST=$(find daily_digests/ -name "*_digest_*.md" -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- 2>/dev/null || echo "")
        if [ -n "$LATEST_DIGEST" ]; then
          DIGEST_BASENAME=$(basename "$LATEST_DIGEST" .md)
          echo "üìÑ Latest digest file: $DIGEST_BASENAME"
          EXPECTED_AUDIO="daily_digests/${DIGEST_BASENAME}.mp3"
          echo "üéØ Expected audio file: $EXPECTED_AUDIO"
          if [ -f "$EXPECTED_AUDIO" ]; then
            echo "‚úÖ MATCHING AUDIO FILE FOUND!"
            ls -la "$EXPECTED_AUDIO"
          else
            echo "‚ùå MATCHING AUDIO FILE MISSING!"
            echo "üîç Checking for all audio files with similar timestamp..."
            TIMESTAMP_PATTERN=$(echo "$DIGEST_BASENAME" | grep -o '[0-9]\{8\}_[0-9]\{6\}' || echo "")
            if [ -n "$TIMESTAMP_PATTERN" ]; then
              find daily_digests/ -name "*${TIMESTAMP_PATTERN}*" -type f || echo "No files found with timestamp $TIMESTAMP_PATTERN"
            fi
          fi
        else
          echo "‚ùå No digest file found for timestamp matching"
        fi
        
        echo "=========================================="
        
    - name: Debug transcript status
      if: always()
      run: |
        echo "=== Transcript Directory Status ==="
        ls -la transcripts/ || echo "No transcripts/ directory"
        echo "=== Digested Transcripts ==="
        ls -la transcripts/digested/ || echo "No transcripts/digested/ directory"
        echo "=== RSS Database Status ==="
        sqlite3 podcast_monitor.db "SELECT status, COUNT(*) as count FROM episodes GROUP BY status;" || echo "RSS database query failed"
        echo "=== YouTube Database Status ==="
        sqlite3 youtube_transcripts.db "SELECT status, COUNT(*) as count FROM episodes GROUP BY status;" || echo "YouTube database query failed or not found"
        
    - name: Upload generated artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: podcast-digest-${{ github.run_number }}
        path: |
          daily_digests/
          transcripts/
          transcripts/digested/
          podcast_monitor.db
          youtube_transcripts.db
        retention-days: 30
        
    - name: Commit and push changes
      if: success() && github.event.inputs.mode != 'test-run'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add all changes including both databases
        git add podcast_monitor.db youtube_transcripts.db
        git add daily_digests/
        git add transcripts/
        git add transcripts/digested/
        git add daily-digest.xml
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Create detailed commit message
          git commit -m "Daily podcast digest update - $(date -u +%Y-%m-%d)
          
          RSS episodes processed and YouTube episode statuses synced
          - Updated podcast_monitor.db (RSS episodes marked as digested)
          - Updated youtube_transcripts.db (YouTube episodes marked as digested)
          - Generated daily digest and TTS audio
          - Updated RSS feed"
          git push
          echo "‚úÖ Committed digest updates to both databases"
        fi
        
    - name: Create release with digest
      if: success() && hashFiles('daily_digests/*.md') != '' && github.event.inputs.mode != 'test-run'
      uses: softprops/action-gh-release@v1
      with:
        tag_name: digest-${{ github.run_number }}
        name: Daily Tech Digest ${{ github.run_number }}
        files: |
          daily_digests/*.md
          daily_digests/*.mp3
        body: |
          Automated daily tech digest generated on $(date -u +%Y-%m-%d)
          
          Contains podcast summaries and audio from the latest tech episodes.