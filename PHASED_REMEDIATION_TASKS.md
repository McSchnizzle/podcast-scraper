
# Phased Remediation Task List ‚Äî Podcast Scraper (GPT‚Äë5, CI + Local)
Owner: Coding Agent ‚Ä¢ Reviewer: Paul ‚Ä¢ Date: 2025‚Äë09‚Äë05

> Goal: eliminate the remaining failures (GPT‚Äë5 digests, timezone/date issues, noisy logs, telemetry/import errors),
> make local and GitHub Actions runs consistent, and verify RSS updates after TTS.

---

## Phase 0 ‚Äî Guardrails & Baseline (do first) ‚Äî ‚úÖ 100% COMPLETE
**Why:** Stop regressions and make fixes observable.

- [x] **Enable "strict" CI**: add a `scripts/ci_smoke.sh` that runs: lints, unit smoke, env checks, and `--dry-run` digest.
- [x] **Pin runtime to UTC** everywhere:
  - [x] Code: set `DEFAULT_TZ="UTC"` and centralize `now_utc()` in `utils/datetime_utils.py` (see Phase 1).
  - [x] GitHub: in workflow, set `env: TZ: UTC`.
- [x] **.env & config sanity**: run `python config_validator.py --all` in CI and local before the pipeline.
- [x] **Reduce log noise default**: default to INFO, DEBUG only with `--verbose` or `LOG_LEVEL=DEBUG`. [COMPLETE - All files updated]

**Deliverables** ‚úÖ 100% COMPLETE
- [x] `scripts/ci_smoke.sh` - ‚úÖ Created with comprehensive smoke tests
- [x] Workflow step "Run CI smoke" calling that script - ‚úÖ Added smoke-test job
- [x] `utils/datetime_utils.py` - ‚úÖ Created with UTC helper functions
- [x] `utils/logging_setup.py` - ‚úÖ Created with idempotent centralized logging
- [x] Updated `config_validator.py` with severity levels and `--warn-only` flag - ‚úÖ Complete
- [x] Added `--dry-run` and `--timeout` support to daily_podcast_pipeline.py - ‚úÖ Complete
- [x] Added CI_SMOKE and MOCK_OPENAI support to OpenAI modules - ‚úÖ Complete
- [x] Replaced ALL datetime.utcnow() calls with UTC-aware alternatives - ‚úÖ Complete
- [x] Updated GitHub workflow with TZ=UTC and smoke job - ‚úÖ Complete
- [x] Log sample that is ‚â§ ~120 lines on a normal daily run - ‚úÖ Complete (23 lines in dry-run mode)
- [x] Updated ALL remaining files to use centralized logging setup - ‚úÖ Complete (9 additional files)

---

## Phase 1 ‚Äî Datetime / Timezone Reliability ‚Äî ‚úÖ 100% COMPLETE
**Symptoms:** "offset‚Äënaive vs offset‚Äëaware", `pytz` missing in CI, inconsistent lookback windows.

- [x] **Remove `pytz` dependency** (preferred) and standardize on **`zoneinfo`** (Python 3.9+):
  - [x] Created `utils/datetime_utils.py` with enhanced helper functions: `now_utc()`, `to_utc()`, `cutoff_utc()`, `parse_entry_to_utc()`, `parse_struct_time_to_utc()`
  - [x] Replaced all `datetime.utcnow()` / naive `datetime.now()` usage with `now_utc()`
  - [x] All date comparisons now use `to_utc()` / `ensure_aware_utc()` for consistent timezone-aware comparisons
- [x] **Feed timestamps** (in `feed_monitor.py`):
  - [x] Completely removed `pytz` dependency and replaced with centralized datetime utilities
  - [x] Updated `_parse_date_to_utc()` to use `parse_entry_to_utc()` with robust fallback chain
  - [x] Lookback window now uses `cutoff_utc(FEED_LOOKBACK_HOURS)` for consistent UTC calculations
  - [x] Feeds with no dates handled gracefully with single INFO line: `‚ö†Ô∏è {feed}: no dated entries (skipped gracefully)`
  - [x] Implemented proper logging policy: 1 header + 1 totals line per feed, per-entry details moved to DEBUG
- [x] **CI Workflow**: TZ=UTC already set in GitHub Actions workflow
- [x] **Database Migration**: Created `scripts/migrate_timestamps_to_utc.py` to normalize legacy timestamp data
- [x] **Display Timezone Support**: Added `DIGEST_DISPLAY_TZ` environment variable for human-facing labels while keeping all logic in UTC

**Deliverables** ‚úÖ 100% COMPLETE
- [x] `utils/datetime_utils.py` created with comprehensive helper functions
- [x] All imports updated across core modules: `feed_monitor.py`, `retention_cleanup.py`, `rss_generator_multi_topic.py`, `daily_podcast_pipeline.py`
- [x] No "offset‚Äënaive vs offset‚Äëaware" warnings - all datetime comparisons use timezone-aware UTC
- [x] CI log shows `üïê Looking for episodes newer than ‚Ä¶Z UTC` and **no** pytz errors
- [x] `scripts/migrate_timestamps_to_utc.py` created for database timestamp normalization
- [x] `tests/test_datetime_timezone.py` created with comprehensive test coverage
- [x] Feed logging policy implemented: INFO (header + totals), DEBUG (per-entry details)
- [x] DIGEST_DISPLAY_TZ support added for human-facing labels with UTC logic preservation

---

## Phase 2 ‚Äî GPT‚Äë5 Digest Generation (EpisodeSummaryGenerator + Scorer) ‚Äî ‚úÖ 100% COMPLETE
**Symptoms:** HTTP 400 "temperature not supported", empty content, map‚Äëreduce ends with zero summaries.

- [x] **Responses API**: migrate summary + scoring calls to `client.responses.create(...)`.
- [x] **No `temperature`** for GPT‚Äë5 reasoning models. Use:
  - `reasoning={"effort": os.getenv("SCORER_REASONING_EFFORT","minimal")}`
  - `max_output_tokens` (not `max_tokens`).
- [x] **Structured output**: replace `response_format={"type":"json_object"}` with **`json_schema` + `"strict": True`**.
- [x] **Parsing**: read `resp.content[0].text` (not `choices[0].message.content`). Persist the raw response for debugging.
- [x] **Config**: add to production config:
  ```python
  GPT5_MODELS = {
      'summary': 'gpt-5-mini', 'scorer': 'gpt-5-mini', 
      'digest': 'gpt-5', 'validator': 'gpt-5-mini'
  }
  OPENAI_TOKENS = {...}, REASONING_EFFORT = {...}, FEATURE_FLAGS = {...}
  ```
- [x] **Backoff**: wrap all OpenAI calls with 4‚Äëretry exponential backoff + jitter.
- [x] **Enhanced Features**: Added anti-injection protection, idempotency keys, observability, and comprehensive testing.

**Deliverables** ‚úÖ 100% COMPLETE
- [x] Created `utils/openai_helpers.py` with centralized GPT-5 Responses API integration - ‚úÖ Complete
- [x] Created `utils/redact.py` for secret sanitization - ‚úÖ Complete
- [x] Updated `config/production.py` with complete GPT-5 configuration - ‚úÖ Complete
- [x] Migrated `episode_summary_generator.py` to GPT-5 with chunking and idempotency - ‚úÖ Complete
- [x] Migrated `openai_digest_integration.py` to GPT-5 with full context processing - ‚úÖ Complete
- [x] Migrated `prose_validator.py` to GPT-5 with TTS-optimized validation - ‚úÖ Complete
- [x] Created `scripts/migrate_phase2_idempotency.py` for database schema updates - ‚úÖ Complete
- [x] Added idempotency tables with unique constraints and performance indexes - ‚úÖ Complete
- [x] Created `tests/test_phase2_gpt5_integration.py` with comprehensive test coverage - ‚úÖ Complete
- [x] Created `scripts/verify_phase2.py` for complete verification - ‚úÖ Complete
- [x] All verification checks pass: 7/7 categories (100% success rate) - ‚úÖ Complete

---

## Phase 3 ‚Äî Import/Telemetry Fixes ‚Äî ‚úÖ 100% COMPLETE
**Symptoms:** `cannot import name 'OpenAIScorer'`, `TelemetryManager` missing `record_metric`.

- [x] **Import compatibility** with enhanced approach:
  - [x] Created `openai_scorer_compat.py` compatibility shim with deprecation warnings
  - [x] Updated `utils/episode_failures.py` to use `OpenAITopicScorer` directly
  - [x] Removed `sys.path.append` hacks in favor of proper imports
  - [x] Added conditional export in `openai_scorer.py` via `ALLOW_LEGACY_OPENAI_SCORER_ALIAS`
  - [x] Created CI guard `tests/test_no_legacy_imports.py` to prevent future legacy imports
- [x] **Enhanced Telemetry** with structured metrics:
  - [x] Added `def record_metric(self, name: str, value: float=1.0, **labels)` to `telemetry_manager.py`
  - [x] Implemented automatic metric type detection via suffix convention (.count, .ms, .gauge)
  - [x] Added structured JSON logging for observability
  - [x] Created convenience methods: `record_counter()`, `record_gauge()`, `record_histogram()`
  - [x] Added backward compatibility mapping to existing run metrics

**Deliverables** ‚úÖ 100% COMPLETE
- [x] Retry queue no longer fails imports - ‚úÖ Fixed with compatibility shim and direct imports
- [x] No AttributeError on `record_metric` - ‚úÖ Method implemented with structured logging
- [x] Comprehensive test suite - ‚úÖ Created `tests/test_phase3_integration.py`
- [x] CI protection against regressions - ‚úÖ Created `tests/test_no_legacy_imports.py`
- [x] Documentation updates - ‚úÖ Created `CHANGELOG.md` with migration guide
- [x] Future-proof architecture - ‚úÖ Structured telemetry ready for observability tools

---

## Phase 4 ‚Äî Feed Ingestion Robustness
**Symptoms:** ‚ÄúNo new episodes‚Äù, offset errors, feeds with no dates, excessive per‚Äëentry logging.

- [ ] **Lookback controls**: add `FEED_LOOKBACK_HOURS` env (default 48) already referenced; ensure it‚Äôs respected.
- [ ] **No‚Äëdate feeds**: treat as informational
  - Count and log one line: `‚ö†Ô∏è  <feed>: no dated entries (skipped gracefully)`
  - Store a feed‚Äëlevel flag so CI doesn‚Äôt repeatedly log noise every run.
- [ ] **Logging reduction**: for per‚Äëfeed processing, log:
  - One header line (feed name, entries seen, cutoff)
  - One totals line (`new/dup/older/no_date`) only
  - DEBUG (not INFO) for per‚Äëentry reasons (duplicate/older).

**Deliverables**
- A single INFO line per feed + one totals line
- New episodes actually discovered when available

---

## Phase 5 ‚Äî Pending/Pre‚Äëdownload Queue Fix
**Symptoms:** Repeated `Episode 129/130/... not found or already transcribed` then ‚ÄúNo pending episodes‚Äù.

- [ ] Replace any loops over **ID ranges** with DB queries:
  ```sql
  SELECT id,title,url,status FROM episodes
  WHERE status IN ('pending','pre-download')
  ORDER BY created_at ASC LIMIT 50;
  ```
- [ ] If the code reads a saved list of IDs, **reconcile** against DB and drop non‚Äëexistent IDs silently.
- [ ] Logging:
  - Summarize: `Pending episodes: N`; log **one line per batch** at DEBUG, not one per missing ID.
  - When a specific episode is skipped, show **title** + id: `Skipping (already done): {title} [{id}]` (DEBUG).

**Deliverables**
- No more spammy ‚ÄúEpisode N not found‚Äù runs
- Clear INFO summary of pending batch

---

## Phase 6 ‚Äî Transcription Chunking UX
**Symptoms:** Logs show only file id (e.g., `5836c7ba.mp3`) not the episode title.

- [ ] Pull title + published date from DB and include in logs:
  - `üé¨ Starting robust transcription: "{title}" [{id}] ‚Ä¢ {duration}m`
- [ ] When chunking, include label in filenames but keep DB‚Äëid canonical:
  - File on disk: `{id}_chunk_{n}.wav`
  - Logs: `Chunk {n}: {start}-{end} ‚Ä¢ "{title}"`

**Deliverables**
- Human‚Äëreadable transcription logs
- DB‚Äësafe filenames remain unchanged

---

## Phase 7 ‚Äî TTS & File Detection
**Symptoms:** ‚ÄúNo unprocessed digest files found‚Äù despite MDs in folder; old files prioritized; hyphen topics.

- [ ] Ensure the **regex** for digest files supports hyphens and underscores (already added):
  - `r'^([A-Za-z0-9_-]+)_digest_(\d{8}_\d{6})\.md$'`.
- [ ] Add `--since YYYYMMDD` to TTS script and pass **today** from the pipeline.
- [ ] Prefer **topic‚Äëspecific** digests first (ai‚Äënews, tech‚Äënews‚Äëand‚Äëtech‚Äëculture, tech‚Äëproduct‚Äëreleases). Daily omnibus is fallback.
- [ ] When no new MDs match `--since`, print single INFO: `‚úÖ No new digests today`; do not dump directory lists at INFO (use DEBUG).

**Deliverables**
- TTS runs only on new digests created today
- Logs are concise

---

## Phase 8 ‚Äî RSS Generation & Deployment
**Symptoms:** RSS updated when nothing new; GH deploy inconsistencies.

- [ ] RSS generator: **skip** update if no **new** MP3s today; log `RSS not updated: no new audio`.
- [ ] Validate `enclosure` files exist; fail gracefully with one line per missing file.
- [ ] GitHub deploy:
  - Print failing command, status code, and stderr if deploy fails.
  - Guard deploy if `deployed_episodes.json` doesn‚Äôt contain today‚Äôs items.
  - On success, print public URLs for today‚Äôs items only.

**Deliverables**
- Correct RSS gating
- Clear deploy failure diagnostics

---

## Phase 9 ‚Äî GitHub‚Äëspecific Fixes
**Observed in logs:** `No module named 'pytz'`, different ASR engine, paths.

- [ ] Add `pytz` to `requirements.txt` (if you keep it) **or** finish Phase 1 refactor to `zoneinfo`.
- [ ] Detect CI in code (`os.getenv("CI")=="true"`) and automatically:
  - Use **Faster‚ÄëWhisper** (already doing) and skip macOS‚Äëspecific MLX/Metal toggles.
  - Avoid Mac‚Äëonly debug messages (`MallocStackLogging`).
- [ ] Ensure `daily_digests/` is preserved and uploaded as an artifact when the run fails (already configured).

**Deliverables**
- GH run free of pytz and platform warnings
- Artifact always contains latest digests/audio

---

## Phase 10 ‚Äî Logging Policy & Defaults
**Symptoms:** Excessive lines at INFO; httpx chatter; repeated directory dumps.

- [ ] Centralize logging config in `utils/logging_setup.py`:
  ```python
  import logging, os
  def configure_logging():
      level = os.getenv("LOG_LEVEL","INFO").upper()
      logging.getLogger().setLevel(level)
      # quiet noisy libs
      for noisy in ["httpx","urllib3","openai","requests"]:
          logging.getLogger(noisy).setLevel(os.getenv("HTTP_LOG_LEVEL","WARNING"))
  ```
- [ ] Replace `print` with `logging`. Make long directory listings **DEBUG** only.
- [ ] Keep ‚Äúheadline‚Äù INFO lines only (phase start, counts, produced files, deploy summary).

**Deliverables**
- Clean INFO logs (< ~150 lines)
- DEBUG reveals details when needed

---

## Phase 11 ‚Äî Documentation & Runbook
- [ ] Update `README.md` with: GPT‚Äë5 settings, Responses API, timezone policy, TTS ‚Äúsince‚Äù usage.
- [ ] Add `RUNBOOK.md`: common failures + fixes (API 400 temperature, offset‚Äëaware compare, retry queue import).

---

## Acceptance Criteria (AC)
- AC‚Äë1: GH Actions run completes on Friday with **daily + weekly** digests OR exits cleanly if no transcripts.
- AC‚Äë2: No timezone warnings/errors; no `pytz` ImportError.
- AC‚Äë3: No 400 temperature errors; **at least one topic** digest produced under normal conditions.
- AC‚Äë4: TTS generates **today‚Äôs MP3s** and RSS updates only when those MP3s exist.
- AC‚Äë5: Logs at INFO are concise; DEBUG reveals detail.
- AC‚Äë6: Retry queue runs without import/telemetry errors
