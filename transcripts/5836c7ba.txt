Welcome to The Vergecast, the flagship podcast of looking for naked singles. I'm your host, Allison Johnson, and that makes sense in this context. I promise it is a Sudoku thing. And on today's episode, I'm talking to a couple of world champion puzzle solvers who started their own YouTube channel where they solve a Sudoku every day. They're ridiculously hard and surprisingly fun to watch. After that, I'm talking to Mark Lavoie, who's one of the pioneers of computational photography and really just phone camera technology in general. We're going to talk about his new camera app called Project Indigo. That's all coming up right after the break. Support for this show comes from Robinhood. Wouldn't it be great to manage your portfolio on one platform? With Robinhood, not only can you trade individual stocks and ETFs, you can also seamlessly buy and sell crypto at low costs. Trade all in one place. Get started now on Robinhood. Trading crypto involves significant risk. Crypto trading is offered through an account with Robinhood Crypto LLC. Robinhood Crypto is licensed to engage in virtual currency business activity by the New York State Department of Financial Services. Crypto held through Robinhood Crypto is not FBIC Insured or SIPIC protected. Investing involves risk, including loss of principal. Securities trading is offered through an account with Robinhood Financial LLC, member SIPIC, a registered broker dealer. This week on Net Worth and Chill, we're joined by Iskra Lawrence, the British model and entrepreneur who's redefining success and what body inclusivity looks like in the fashion industry. From facing rejection for her curves to building a thriving business empire centered on body positivity, Iskra shares her unconventional path to financial freedom. I had this chunk of money, and luckily, I decided it was time. I was like, I am never going to feel disposable again. Fuck this. Listen wherever you get your podcasts or watch on youtube.com/slash yourrich BFF. All right, we're back. I am joined by two very special guests: Simon Anthony. Hi, Simon. Hello. And Mark Goodliff. Hey, Mark. Hi there. They are puzzle champions, but more importantly, the hosts of a YouTube channel called Cracking the Cryptic. And I guess I'll let you guys explain what that is, what you do there. Simon, maybe can you give our listeners a quick rundown if they're not familiar? I can, but it'll sound mad. Cracking the Cryptic is a YouTube channel where we solve variant Sudoku puzzles sort of live on camera a couple of times each day. And the channel's been going now for about eight years. Oh my gosh. And it's become really quite popular. So we have about 650,000 subscribers now. And the average length of a video is perhaps 45 minutes to an hour. So people are spending time with us every day having a go at these puzzles and then watching us attempt them. Yeah. And because it's live, it's all of the mistakes, you know, all of the poor thinking is there. But in the end, hopefully we solve the puzzle. And that's what we do. Yeah. And we each post a video every day. And in addition to that, there's a weekly cryptic crossword masterclass as well. And we solve Wordle every day as well. So, there's a lot of content and it keeps us very busy. I really appreciate the Wordle videos. They make me feel, they usually make me feel better. I'm like, okay, this wasn't as easy as I thought it was. And if you could explain really quickly, so I discovered your channel because I got into Sudoku, but I am more familiar with I think what you call classic Sudoku. Could you explain just the basics of classic Sudoku if people are not familiar, but also how it escalates from there and the kind of puzzles that you guys tackle? Sure thing. So, in normal Sudoku, you get a grid of nine by nine cells, and you have to put the digits one to nine once each in every row, every column, and then there'll be nine three by three boxes in the nine by nine grid, and each of those three by three boxes mustn't have a repeated digit either. And that's the game that I think most of us are familiar with when it first came to the West, I suppose, which was in early 2000s. And variant Sudoku takes that and sort of turns it up to 11. So, you might have extra graphics in the grid, there might be a thermometer wending its way through the grid, and you'll have to increase the digits along the thermometer from the bulb end. And then it can get crazier and crazier from there. We've got puzzles now where there's a rat in the grid that has to get to a cupcake going along certain pathways. We've got puzzles where most of the grid is covered in fog and you can't see it. When you get a correct digit, some of the fog will clear. So, the puzzle is revealed to you gradually. And these puzzles have all been handmade. So they're very, very different to most people's experience of Sudoku, which will be on the back of newspapers. All of those puzzles are made by computers. Whereas the moment you solve a puzzle that's been created by one of these fantastic human brains, it's a different experience altogether. And I think that's why the channel has become popular: people are suddenly seeing just the art that can be found in the puzzle form. I find that so interesting because maybe one of the things I do when I get into a thing is be like, how is this made? I want to take it apart, you know? So maybe if you could talk a little bit about how you mention a lot of Sudoku, classic Sudokus are computer generated. Were they always like that? Is this like a recent thing? And how can you tell the difference, you know? Well, I mean, originally the puzzle was invented in Japan by a company there called Nicoli, which is a wonderful place of innovation. And all of their puzzles are handmade. But when the puzzle came to the West, it was Wayne Gould originally, I think, a New Zealander, who invented a computer program that could just churn out zillions and zillions of puzzles. And he managed to sell it to many of the newspapers in the Western world. And so it just became accepted that, you know, you could have computer puzzles, and everyone seemed fine with that because they'd never experienced anything different. Whereas when you solve a Nickel-cly classic Sudoku, so the classic Sudokus that you were originally used to, Alison, you know, when you solve one of these nickely puzzles, it's completely different because the constructor has built into the puzzle sort of a trail of breadcrumbs, and you can feel what they want you to find at the particular points. And there's normally some really beautiful logic packed in there, which you just don't find in the machine-generated puzzle. So, yeah, it's a big difference. Yeah. When we started the channel, we were mainly solving classic Sudokus from, say, the New York Times or something, and they would all be computer-generated, and they would often have a very standard kind of trick to get them done. And we would go through that. But then, gradually, as we got going, we wondered: would it be interesting to show people the sort of variant Sudokus from world championships that we'd experienced that were a bit more interesting in a way? And unbelievably, this whole community grew up watching these videos and going, oh no, that's really interesting, Sudoku. And I think almost all the setters that we feature on the channel now, and we basically take submissions from people as a good puzzle to do on the channel, almost all of them grew up, learned about variant Sudoku from our channel. So it's marvelously organic in a way. Yeah, I was wondering if you could talk a little bit about the community because I think there's an interesting moment, you know, with any kind of creator on the web, you know, whether you run a website or a channel, where we're sort of discovering just the real value to having a community, and that's kind of what people want. So, how do people connect with you? You mentioned they suggest puzzles, but how else are you interacting with your community? One of the things that happened to us, you have to bear in mind, we're sort of middle-aged guys, we're not tapped into things like Discord. But when the channel started to get bigger, we got approached by some people who watched it and said that you really should have a Discord channel associated with your YouTube channel. And we were like, oh, that sounds good. And they said, oh, we'll take on the sort of role of setting it up for you. And we thought, oh, that'll be nice. I think there are now nearly 40,000 people in this Discord server. Oh, wow. And all trading ideas, all solving puzzles for each other, trying to push forward the boundaries of what's possible in Sudoku. I mean, I shudder to think what the combined IQ is of the people on there, but there is some serious weaponage in terms of intellectual firepower. And one of the lovely things about Cracking the Cryptic is that actually the community is remarkably kind. It's something we've always encouraged, you know, kind comments, positivity. And people really seem to take that to heart. And I think most of the internet now is probably a place where blood pressure gets raised, whereas Cracking the Cryptic is a place where it sort of gets calmed a bit. And yeah, it's attracted people to it who are in general very decent and normally very bright as well. So I get a lot of imposter syndrome. At least I do. Oh my gosh. I mean, having to solve everything live and kind of be on your feet like that. Is it a challenge every day? Do you get kind of nervous? It is daunting. It is a worry that you sit down in front of a puzzle. And if it goes wrong, I mean, if it goes completely wrong and you can't solve it, we don't have to put up a video. So there's always that get out, but that's kind of a rarity, I think, for both of us. And most of the time, if you do make a mistake, well, you have to kind of backtrack and find it and work out what you did wrong. And people are very generous about that as well. I think, as Simon said, the levels of kindness are very high. And the great setters and theory creators seem very keen to still interact with us, even though I suspect we've been revealed as not the great brains that people maybe thought we were at the beginning. But it is just a pleasure to deal with almost everybody on the site through Discord in the comments. We get emails. We put our email address out every day and we get hundreds of emails, as I say, puzzle suggestions, but also lots of general comment. I think we were amazed at the beginning when it started to grow. And people would tell us something like, oh, I fall asleep to you every night. And we weren't sure whether that was a compliment or an insult. But gradually, there was a period, and it's probably still ongoing, where we get about one email a day about how we've seriously helped someone's mental health to, you know, from extreme levels of stress sometimes. And we've had at least three doctors tell us that they would have given up their course, but the calm logic that we allowed them to see enabled them to keep going in their studies. And it's just an amazing thing to have that kind of impact with no thought or plan of doing so. Yeah, yeah, there is kind of strikes me as like solving a puzzle is a pretty solitary activity. I mean, it kind of has to be unless you're doing a jigsaw puzzle with your friends or something. And sort of personal in a way. Like when I sit down to do Wordle every morning, I feel a little embarrassed to like show other people my guesses. You know, you're, you're sort of like, it's sort of like when you talk on the, you're like ordering a pizza on the phone. And I don't, I'm like, I don't want anyone else to hear me, like working this out. So I wonder if there's an element of just, it feels like you're exposing something a little bit and people are connecting to that in a way where it resonates, I guess. I think that there's definitely something to that. I mean, it is nerve-wracking to actually solve. And because all of the thinking you're doing is live, I mean, I still get this shot of adrenaline. If I have to do mental arithmetic, because some of the arithmetic we have to do, it's, you know, you could be multiplying some reasonably big, you know, two-digit numbers or something like that, but you might be having to find the prime factors of something that's not trivial. And it's, you're sort of there thinking, people are going to be watching me thinking, he's so stupid. Why can't he do it more quickly? And, you know, you've got this devil on your shoulder the whole time chirping away about how you're being dumb. And you have to ignore him because he's just a very annoying creature. But he's definitely there. Yeah. We also have different strengths, I think, Alison. Well, sometimes I marvel at Simon's instinct for a break in a puzzle that's complicated to start. And I just can't see how he's honing in on the right spots as he so often does. He's, I understand, jealous of my sort of basic Sudoku mechanics and maybe some of that mental arithmetic as well. But, you know, these are the skills that I think are trivial. Whereas he has skills that, you know, I can sit in front of a really hard puzzle for 20 minutes, half an hour, 40 minutes, just not knowing what to do. And it just feels dreadful in a way. But, you know, you learn over time that if you keep worrying away at it, you can. And this is very important to remember that the constructors are setting you a puzzle that they want you to have fun with and struggle with, but they want you to get there. So there is this trail of logic defined. And when you do light on it, you get this wonderful epiphany. And I think that's what keeps people coming back to the channel is watching those moments where you suddenly understand something. And that's joyful. No, hang on. Maybe it's no, it is the same. If that's a six, I can't put a one here. And this is a six in box five, which puts a one here. So you can't put a one either side of it. So here we go. So now I've got, now I know that there's a six in this domino, which means this is not a six. This is a six, which means this is a one. This is a two. And we are cooking with gas all of a sudden. Yeah. I don't know if I'm just like keying into this because I've been interested in Sudoku, but there's a lot of like puzzles seem to be having a moment. Like I know a friend of mine is addicted to the puzzles in the LinkedIn app and like opens LinkedIn every day. And I'm sure there's an element of they've discovered, you know, they can keep people coming back every day and get those like daily user numbers up. But what do you think that says about like BBR moment culturally or what puzzles are doing for people? I think there's a there's a lot to unpack there. I mean, I think LinkedIn has really it dodges most office firewalls, of course, which means that it's absolutely brilliant. If you enjoy having a few minutes out every day, and you can, a lot of puzzle websites tend to be blocked from my experience, but LinkedIn probably won't be. You know, so that's a good thing. But I also sense that there is being a bit geeky or nerdy, which I've been throughout my life. I mean, same. Yeah, I've never, never been cool, popular. My sister has relished throughout my life, you know, telling me how useless I am in all social situations. But now it just feels, I don't know whether it's AI or, you know, computer programming becoming everywhere, isn't it? And so necessary for so many parts of life. But it feels like, or the popularity of things like escape rooms as well. Or maybe it's the mindfulness that comes with doing puzzles, as you've found. You're sort of, when you actually have to focus on a puzzle, you're taken away from maybe the worries of life for a few minutes. You have to focus on what you're doing, or you probably won't get very far. And it brings a calmness. And maybe people value that in this day and age more than they perhaps would have done 15, 20 years ago. Yeah. I think the way you expressed it, Alice, is absolutely right. Puzzles are having their moment. But in a way, what it is, is I think people are in this moment discovering puzzles and finding out how much fun they are. I come from originally before Sudoku from a world of cryptic crosswords. And people have often asked me why, you know, why are you doing, or now it's obvious, but in the old days, they would ask me why you're doing this old man's pursuit. And I was saying, well, it's not, doesn't have to be. Basically, once you find the joy of cryptic crosswords, there's no reason ever to stop doing them. And people don't. And therefore, the average age tends to skew older than for pursuits that people will give up when they've had their fill. But you don't do that. And I think it's true about Sudoku as well. People stay with it. Even if they don't stay with our channel, I think they stay with Sudoku and with puzzles. And, you know, we've been part perhaps of leading people to discover puzzles. And that's great. And I think it's more that people are sort of free to enjoy them now rather than that they hadn't thought of them before. I'm curious actually about kind of the tools you use in your puzzles because I think maybe Simon, you mentioned in a video that you sort of prefer puzzles that you can just think through. And there are tools that exist for super hard Sudoku that like help you math your way out of it. I don't know. Can you kind of talk me through like the tools you do and don't use when you are solving puzzles? Yeah, I mean, we both use compute, obviously, because we're recording something we're doing on a computer. We have some great software that's been created by Sven Neumann, which is very, very good. It allows us to employ some techniques that are much harder to do if you've just got a pencil. So, for example, we can color in. Cells, or we could even draw lines through cells. And when we're solving these harder puzzles, things like that, they're pretty useful. The software, even I mean, we don't use it, but it'll allow you to compute all the different ways of adding up to 25 with four digits. It'll actually give you a list of all the ways that you can do that. So if you don't like doing the arithmetic, you can still, you know, access the puzzle. But I think, as with anything, what you find is you build up your own personal tool of, I don't know, tricks, techniques, and you cycle through those. And that only really comes with experience. And I guess now Mark and I have a lot of experience. So we've got something like 4,000 videos now, Mark. Oh, my gosh. I think it may be 5,000 now. Okay, 5,000. Oh, wow. Yeah. Yeah. It's a bad catalogue. Yeah, it is. You do build up a lot of experience and it's often very helpful. And yet, still every few months, something completely new is kind of forced in upon us by a brilliant constructor. And we learn something totally new about, even sometimes about a basic Sudoku grid, that it must have some property that we didn't know before. And that, you know, I still think in some ways this is the dawn of Sudoku, which is brilliant. Mark's right. I mean, there was a mad thing we discovered the other day for the first time, which is sort of if you check, imagine that you've checkerboarded your Sudoku, the sort of internal checkerboard you've created. Any digit you put in that has to appear an even number of times in that internal checkerboard, which it's like, why? Why is that true? And yet, sort of geometrically, mathematically, it is true. But we didn't know it. I didn't know it before I did that puzzle. It was completely, it's like it's a truth that exists underneath the surface of the puzzle. It's not going to help you solve a classic Sudoku, but it's there. It's just sitting there like a mathematical truth. It's extraordinary. Yeah, there is something really satisfying, I think, in discovering new layers of something you've been enjoying. I do want to touch on a puzzle you did. This was, I guess, went viral. We wrote about it on the verge. This was the miracle Sudoku. Is it right? And Simon, you solved this one. Can you describe what this puzzle was and kind of how it went? Well, I can. I mean, but really, it was Mark's fault. So, what happened was we got sent a puzzle by a constructor called Mitchell Lee. And the very, very unusual thing at the time about this puzzle was it looked like a normal Sudoku, except rather than having several digits in the grid, there were only two digits in the grid. It was a one and a two, and that was it. And Mark sent me an email and said, It would be good if you opened this live on camera. So I took him at his word, set up my machine, loaded it, having started the recording, and was faced with this. At that time, it just looked stupid. I thought he'd just done it as a joke. Let me just see if I can put that in there. Let's see what we get. Right. He's got to be joking. There is no way that this, well, it might have a unique solution, but it's not going to be findable by a human being. I suspect this is going to be a short video because he is trolling me. And so I very nearly, thank goodness I didn't, I very nearly turned off the webcam and sort of called him in high dudgeon. But no, I could see one thing at the start that I could possibly do. And so I did the thing. And then it was amazing. After, you know, a few more steps, I could see something else. And it was one of those puzzles where you sort of, it was like a snowball, you know, starting an avalanche. All of a sudden, you could, this pattern emerged. And you could, at the end, I did solve it. And I think the reason it was popular was just my sheer astonishment that this could exist. That you could, yeah, that somebody had had the idea, that somebody had made it. And also that this impossibility was actually solved in about 25 minutes. It was just bizarre. It was bizarre. Exactly my finding when I tried it before Simon had seen it. Yeah, and something, if people aren't familiar with the channel, you can solve along with these puzzles. So that's exactly what I did. You know, watched you get started with it. And then, yeah, you look at it, you're like, there's no way this could be solvable. But I saw you, you know, go through the first kind of steps and tried it on my own. And, you know, I had to like rewind a couple times and see what you were doing. But it's so cool to kind of go on that journey with you where I'm like, oh my God, I am solving this. Yeah, it just, I had a lot of fun with it. Yeah, I mean, it was, it was remarkable. I mean, we got emails from all over the world as a result of that. It was, it was like a moment where, you know, they say everyone, everybody has their 15 or five minutes of fame. It was like that spotlight suddenly turned on us for just a scintilla of time, and you sort of got a bit of the glare of a little bit of publicity. And it was, it was very enjoyable because it was so brief and unexpected. Yeah. And a positive, I think, you know, if people are discovering it and having like a joyful moment of like, I can't believe I just watched this 25-minute long video, which is, I think, interesting. And you kind of touched on this, I think, that your videos are long, like, you know, comparatively in the age of certainly TikTok, where you watch for a few seconds and scroll on. Can you talk a little bit about why you're able to enjoy having such a long amount of time to show what you're doing and talk about what you're doing? We thought that people would just want to see the technique, would just want the lesson. And then we kind of thought, well, they won't want to watch the rest of the solve. That's just filling in the numbers. And we would try things like speeding it up or putting music to it. And they got really annoyed. They said, no, no, no, no. We want to see you solve it till the end. And it is, I think it's what you said earlier that people want to come on the journey of the solve and they want to be part of it all the way. Some people treat it like sport, like a spectator sport. And until you put the last digit in, the final whistle doesn't blow. So it's still going. And that extends into the longer videos. I mean, Simon's done videos, is it three hours you've done now, Simon, in a single puzzle? Four hours, 10 minutes is the longest puzzle. And you'd think, oh, well, that can't be popular because how can it possibly be the case that anybody would want to watch a man-solve a Sudoku puzzle for longer than the extended edition of Return of the King or something? It cannot be, it cannot be right. And yet, and yet it's one of our most popular videos of recent times. It's like people get invested in it. And in fact, on that video, it's one of my favorite comments underneath the video that we've ever had, which was from a guy. And he said, 15 years ago, I watched the whole of the Twilight series with my girlfriend on the condition that one day she would watch something of my choice without complaint. Tonight's the nights. Oh my gosh. Yeah. Personally, I'd rather watch four hours of puzzle solving, but yeah, I can see how that trade was made. Incredibly, those long videos get more average watch time percentage than the shorter ones. It just defies belief, but people do enjoy the, I think they love seeing us challenged. They love the struggle because they're being challenged as well at the same time. And, and you know, it's there's an extent of seeing what the human brain can achieve. And I'm talking about the constructors more than us, but there's us as well. Well, thank you so much for joining me. This was a delight. And I hope people will check out Cracking the Cryptic on YouTube. And I'm going to be seeing you again soon because I'm going to be watching your videos. Thank you. Thanks, Allison. It's been a pleasure. Yeah, absolutely lovely. Thanks, Alison. We need to take another break. When we come back, we're going to be talking to Mark Lavoy about his new camera app, Project Indigo. It's coming right up. Imagine a future where you can open your phone and call a flying taxi. Long just fantasy, flying taxis are startlingly close to reality. Or so say my guest this week on Solutions with Henry Blodgett. Next decade. We'll be certified in 28. We'll be producing these things in 29 and 30. And then it's off to the races. Mauriti Stanley put out a report saying this will be a $15 trillion tan by 2050, much larger than the automotive market. This week, I talked to the CEO and a major investor of vertical aerosol. Space, one of three companies trying to make flying taxis a reality. Follow Solutions with Henry Blodgett to hear more. What is up, people of the internet? My name is Marquez Brownlee, aka MKBHD, and some of the biggest smartphones of the year are about to launch, including the brand new iPhone 17s around the corner with a model you've never seen before. So, on the Waveform podcast, myself and co-hosts Andrew Manginelli and David Emil gather the biggest tech news of each week and then discuss at length everything we're excited about and sometimes things we're not so excited about. So, this time of year, we like to call smartphone season. So, if you're interested in hearing all the latest releases from Apple, Samsung, and Google and others, be sure to check out the Waveform podcast on Spotify, Apple Podcasts, or wherever you listen. See you there. Welcome back. I am joined by someone who, for a portion of our audience, will not need an introduction, but we'll do one anyway. I'm here with Mark Lavoie. Hey, Mark. Hi, nice to be with you. Thanks for joining. Mark Lavoie is a professor emeritus of computer science at Stanford. But right now, and what we're going to be talking about, he is a VP and fellow at Adobe, where he has been working on a new camera app, also known to a lot of people in our audience in particular for his work on Google Pixel Camera for many years. So, thank you for joining me. It's great to be here. So, I was wondering if you could give us maybe a shortened version of your bio. There's a lot of interesting stuff on there, you know, some of which I just touched on. But then, catch us up a little bit on what you've been doing since you've been at Adobe. A shortened version of the bio. Well, I seem to have wandered from topic to topic roughly every 10 years. So, in the 70s, I worked on computer-assisted cartoon animation at Cornell. In the 80s, I worked on medical imaging at University of North Carolina. And then at Stanford, in the 1990s, I worked on three-dimensional scanning, including the Digital Michelangelo project. In the 2000s, I worked on light fields and camera arrays, built some big camera arrays at Stanford. And in the 2010s, largely at Google, I worked on computational photography, including, as you said, for the pixel phone. Yeah. You joined Adobe in 2020. Is that right? Right. During the height of the pandemic. Ah, an interesting time to switch jobs. I did it too. Indeed, indeed. Yeah. So, and you spoke to our editor-in-chief, Neil I. Patel, around that time. And the stated goal was to create a universal camera app. And it's been five years since then. You've released that camera app called Project Indigo. Can you give people the quick elevator pitch if they're not familiar with it? I know a lot of our audience is. It depends how long the elevator is. So the basic idea there is there are a number of limitations of most smartphone camera apps. I'm certainly familiar with those limitations. There's a smartphone look that a lot of people don't like that might look okay on the small screen or in bad lighting, but don't look okay if you look at that same image large. It's very bright. It's contrasty. The shadows have been raised a lot. The edges are very sharp. The saturation is boosted. It's a certain look. As I said, it might look fine on your screen, but not if you're trying to make something larger out of it or even look at it on a large screen. Another issue with most smartphone camera apps is they don't offer much in the way of manual control. Some of the third-party apps do, but then they don't offer the third thing, which is computational photography. So our computational photography meaning combining multiple images to make a better quality image, regardless of the look. So we wanted to combine all three of those things: a more natural look, full manual controls, and the best computational photography the state of the art allows. Okay. We also wanted to release some fun stuff on the side. So we have synthetic lung exposure, we have removing window reflections, which also ships in Lightroom and Camera Raw. You call this look kind of HDR-ish, which is, I think, a different thing from HDR as a term. Am I right in thinking that? Do you have that same kind of sense of it? Yeah, yeah, yeah. It's a little bit confusing. So HDR just means that there's some way you can display stuff that's really bright. And to some extent, just the hardware of the phones allow this. They are very, very bright. And certainly some display screens, computer monitor screens, are also very bright. There are these great ads or reviews where someone puts on a pair of sunglasses before they even look at their screen. So that gives the capability to display HDR. But the real world can be even brighter. And not all phones can display HDR as being really bright. So in either one of those cases, a scene that's really bright or a display that's not so bright, you need to tone map it in a way that fits all of the dynamic range, meaning the range from black to white, into whatever the display can do. That usually involves lowering the highlights and raising the shadows. If you do too much of that, that's what people call the HDR-ish look. Can you talk a little bit about like how we ended up here with this look? Well, they want the whole image to be readable. And they want people to be able to take photographs in very challenging lighting. So they'll take a backlit portrait with a sunset in the background at the beach, but they still want to be able to see the features of the person who is silhouetted. That's a very high dynamic range situation. And they'd like to be able to share it. So they want it to look readable. And so they'll raise the shadows a lot. And that can lead to this HDR-ish look. In particular, if you're looking at a small screen in bad lighting, so bad lighting might, for example, be a very bright day where there is glare on the phone surface, then they want to make sure it's readable there too. And so they'll raise the shadows and lower highlights. But if you take that same image and look at it in a slightly darkened room or on a larger screen, then that's where it begins to look, as you said, grayish or too squished toward the middle. In the past few years, maybe it's been kind of brewing longer than this, you know, the Ultra HDR format has kind of come to prominence, which is related and sort of in the mix here, but is a different thing than the two things we were just talking about. Can you explain what that is? I know, you know, Android supports Ultra HDR. Apple has a version they support. Just what is this at the basics? So both of those are closely related to and were co-developed with Adobe's format for representing high dynamic range images. As a matter of fact, Apple's Paul Hubel and Adobe's Eric Chan presented the format together at a conference. Okay. So it's really a co-development. Ultra HDR is just a brand name. The basic idea is that a file ought to contain two images: a base image, which is what you would display if you only had a standard dynamic range display. In other words, not a super bright display, SDR for short. And a separate image, which is what's often called a gain map, meaning how much would I add to that if I had a brighter display? And that's the highlights part of it. Now, it's a little bit more complicated than that. It can be done as either an addition or a subtraction, but that's kind of the basic idea: that there are these two images. And if you have an HDR display, then the idea is that the viewer, meaning, for example, the browser software, would add the two together and then display that. So that's what all of these HDR formats have. There are other HDR formats. AVIF has one. But the world seems to be moving gradually toward either the Ultra HDR or Apple's HEEK format or ours, which is this JPEG that has a base image, which is SDR, and a base plus gain, a gain map, which gives you HDR. Why does this one seem to be the one we're landing on? And does it solve our problems with HDR and HDR displays and HDR-ish photos? It's arguably better than the other ones because it really kind of separates out here's what you would see if you had it only an SDR display, and here's what you would see if you had an HDR display. And it also means that in image editors like Lightroom, you could separately tune the two looks because you might want a different crushing of shadows or lowering of highlights for standard dynamic range display and for high dynamic range display. Or you might just want an SDR image and you never want the highlights to be bright. And so in Lightroom, again, you could toggle off the HDR and just sit there and adjust for SDR. So it's a good format. I don't know if it's the best ever, but it's a good format. And it's nice to see that it's being gradually adopted. Gradually, of course, is very gradually in this fragmented world of ours. So social media apps are only slowly coming on board with this format. Yeah, there's so many components to it. There's the, you know, the camera, there's the display on the camera, there's where the photo eventually ends up. The display of the person who's looking at that photo on Instagram. And I think something I've seen in me, you can let me know if you've seen this too or not, but I'm seeing kind of an association from photography kind of like literate people where they have just gotten a bad taste in their mouth with HDR and they sort of say HDR is a bit like a dirty word. I'm trying to evangelize the ultra HDR a little bit, you know, like this is a different thing. Do you see that conflation happening? Absolutely. I think you're right. But what they're conflating is the ability to display HDR and the particular tone mapping and look that has been used on HDR-capable photographs. And that's this over-tone mapped thing. And so I think it's possible to display HDR images in a way that doesn't have this look. Interestingly, it's also possible to overdo the look on purpose in a way that's actually artistic. And one person I think of there is Trey Ratcliffe in Stuck in Customs. He's got this great image, one of his signature images, of the landscape around Guilin in China that is ultra-wide angle and very over-tone mapped on purpose and made saturated in a way that makes it look like a fairy tale landscape. So that's art. Right. That's obviously not the way it looked, but everyone knows that when they look at it. So I'm separating out this art from it. But for ordinary photography, I think you're right. But the answer is that it's in the tone mapping. There's nothing inherently wrong with the HDR capability. Okay. Well, I'm telling everyone that Mark Lavoie says I'm right, and I will take that to my grave. You know, one funny thing about this is there were videos made while I was at Google about, oh, the look of pixel phones is learning from Italian art. And I talked about my preference for Caravaggio and so on and so on. Well, those are all standard dynamic range images. They're just reflective. They're not luminous. They can't do anything brighter than the white of the gallery wall. And so we sort of do need different models and artistic models and a different artistic exploration as we start to do high dynamic range. And I think the world is still experimenting with what it ought to look like. Yeah. How far is too far? What do we all like and dislike? Yeah. How did you think about that going into developing your camera app? You know, I've used the app certainly quite a bit. I know a lot of our readers have, but the kinds of things that people can expect, maybe as far as HDR processing when they use Project Indigo. Right. So I led a team of people who determined the taste for the early pixel cameras. I don't know if I would go so far as to say I was the tastemaker, but I was one of them. Here at Adobe, I've let Florian Kynz, who co-wrote the blog with me, be the lead tastemaker. And you can see his taste in all the photographs that are on the blog. They look natural. They look like, oh, if I were there, I know what I would have seen. They don't look like there's been some deliberate adjustment in tone mapping. They look like, if I had an SLR with enough dynamic range, that might have been what the picture looked like. And so one of the characteristics is let dark shadows be dark. And I think a lot of people just like that. Yeah, I know I do. There's, to be honest, we've kind of fell into this moment of a trend toward retro and toward film looks, which are more natural looks because there's no adjustable tone mapping, or there's very, there are fewer ways of doing adjustable tone mapping in film. And people like that. And they sort of heave a sigh of relief, like, okay, you know, that looks like a plausible scene. And the darks are dark. And we like dark because it's the et cetera principle. You know, what's the mystery in that dark area there? And I like that. And Florian likes that. So that's kind of what we allowed to happen on Indigo. Yeah. I should point out, though, that it's a profile. If you load it into Lightroom or Camera Raw, it shows up, says Indigo, and you can change it. In particular, if you've been capturing DNGs, which means raw images, you can change it to any profile you want. You can add presets to it. You can make your own look. So it's not like we're demanding that this is the look that you would produce with that app. It's our suggested look, but you can change it. Yeah. And kind of along the same lines, I wonder if you can talk about the raw capabilities. I'm someone who kind of poo-poos shooting raw on a smartphone. I tend to want to let it just do its thing. And that might be an older way of thinking about smartphone photography, especially with computational raw, which you've brought into Project Indigo. Could you explain quickly what that is and why that was important to have? Right. So if you do JPEG-only with Indigo, you'll get our look. If you bring it into an image editor, Lightroom or any other editor, you can make minor tweaks on it, but you can't do anything really major. Because the characteristic of any of these tone mapping methods is that the highlights in one part of the image might be the same pixel value as the shadows in another part of the image. And so if you use sliders or tone curves or anything to raise one or lower one, you might raise or lower other things you didn't want to lower or raise. Even though they were actually different brightnesses in the original scene, they got tone mapped to be the same pixel value. So this is the main reason why people like shooting raw, because the numbers that are in the file represent relative scene brightnesses just as sensed. And then you can keep the shadows separate from the highlights if you wanted to. So that's the main reason for shooting raw. Now, you say you don't really like or have not really shot raw on smartphones. So the reason for that is that the raws have not been very good. They both don't come with a very good look, and they often don't come with computational photography or enough computational photography. So in low light, they look noisy. On some phones, which I won't name, if you switched into raw mode, it would take a single frame and end up be very noisy because the smartphone sensors are small. So, the right thing is to do this computational photography where you align and combine multiple frames, even to produce the raw. Now, some purists would say, well, that's not raw anymore because it was captured over a number of frames. That's true. But it still has the major characteristic of raw that it's proportional to scene brightness. And you can do any editing you want without worrying that you're adjusting both shadows and highlights at the same time. Yeah. So I do recommend that you try raw in Indigo. I think you'll like it. Yeah, yeah. And I have made an exception for Indigo, definitely. Just knowing I'm not throwing away a bunch of extra frames and extra data. Yeah, it's been a totally different experience shooting with the phone. I use the phone cameras on every major phone, you know, released in this country. And this app really made me think about it differently. So one characteristic, I mean, there are trade-offs. You know, why didn't everyone else do the same thing we did? Well, we're capturing more frames. It takes longer to put them together. You have to be a bit more patient between shots, particularly in low light. So there are trade-offs to be made. And we made a particular trade-off favoring the more serious photographer, the one who cared more about image quality and adjustment after the fact. I think someone who really wants to get into the nuts and bolts of photography, it sort of speaks that love language where just right from the onboarding screens, you know, you learn a lot about what the camera's doing and how things will be processed. And with your background as a teacher, I wonder how that, did this feel like a natural kind of fit? Did you find as you were developing this app, you were sort of bringing that part of your background along too? Yeah, I love teaching. Maybe I sometimes talk too much, but I want people to understand. And so the last course I taught before I left Stanford first for Google and then for Adobe was a course on digital photography. And I would teach both the art and the science. You know, why do we want to combine images? Where does this noise come from? What are aberrations on lenses and things like that? And so that kind of spilled over onto the explanations that I made both in the blog and on the opening screens in Indigo. I want people to understand. How do you think about that? Maybe line is the wrong word, like a line between the art and the science. I think in photography, especially, people can get kind of, they'll want to dive into one or the other and they'll see, you know, they want to know everything about how the camera's working and they get into the nuts and bolts, or they don't want to get into all that and they feel like it detracts from enjoying the art. How do you? Are those two opposing things? Can you exist in two different states at once? I don't consider them opposing at all. I do understand tastes that some people are just nerds about the science and some people are nerds about the art. One of my heroes is Ansel Adams. So Ansel Adams, first of all, was a teacher in addition to being a great artist, but he also embraced both the art and the science of photography. He wrote three amazing books, The Camera, The Negative, and The Print, which are quite scientific and full of careful illustrations of how perspective works and the zone system for exposure and so on. I had a chance once to ask one of his assistants, his longtime assistants, would he have embraced digital photography? He did have a chance to test a very early digital camera, but would he have embraced it for his photography? Without a moment's hesitation, the assistant said, of course he would have. Just look at his work and his books. Yeah, it makes sense. And I think a lot of photography conversations go back to Ansel Adams, sort of inevitably, when you talk about processing, Photoshop, you know, maybe even the moment we're in right now with generative AI, you kind of can trace back to like, well, we think of photography as this, you know, you're just, it's just photons hitting a piece of film or a sensor. But the way Ansel Adams, you know, manipulated images and the things he did in the dark room, people are maybe not aware of. Exactly. And not only that, so first of all, you're exactly right about the manipulations in the dark room. His dodging and burning, which many photographers know about, is local tone mapping. It's the same as this raising the shadows in one part of the image and lowering the highlights in another part of the image, but maybe not in all parts of the image. That's just dodging and burning. But more than that, he was open about it and taught about it. He has one great book that is The Making of 40 Photographs, I think it's called. And he shows the original and the version after he has fiddled with it in the darkroom or interpreted in the darkroom. In fact, one of his most famous pictures, The Clearing Winter Storm in Yosemite, is a great example that I used to show in my photography course at Stanford of the original, which is surprisingly, I wouldn't say bland, but fairly even-toned and not nearly as exciting as his version after dodging and burning. And he would explain what he did and why. It's such a joy to hear someone who is so immersed in what they do and has such a love for it and the technical mastery, I think. So, yeah, I definitely need to check more of that out. I have some other questions about Project Indigo before we stray too far into philosophy of photography and art. I'm wondering your thoughts on generative AI. And particularly, it's on my mind because I've just been using the Pixel 10 Pro, and there is a Zoom feature on the camera that instead of using just digital Zoom, which has a lot of limitations, takes your image and uses a diffusion generative AI model to kind of fill in the gaps. And as your former colleague Isaac Reynolds said, squash the artifacts. So that's sort of out there now. Is that something you would consider bringing into Project Indigo? A lot to unpack there. Yeah, it's really good. First of all, in general, generative AI definitely has a place in the future of art, the future of photography. The Gen Remove feature in Lightroom is generative AI, and I use it to remove distractors in many of my personal photographs. It's very useful. Of course, it can be used to make entirely new stuff, and there's a place for that as well. So as far as digital zooming goes, I don't want to talk specifically about pixels, but there are other smartphone vendors who have explored extreme zooming like that. Any smartphone that does say 100x is, of course, using digital zooming of one digital scaling of one kind or another. So maybe I can answer it by giving a general way to think about this. If they are claiming 10x zoom over the over what the lens can do, or 20x over what the lens can do if it is a native resolution that's a 5x lens, but let's take the 10x case. Then the way to think about it is every 10th pixel, horizontally and vertically, is real, which means that considering both horizontal and vertical, one out of 100 pixels is real. The other 99 have to be made up. Now, how do you make up pixels? You could just interpolate smoothly and make a blurry image. You could try to sharpen edges. Now, why would you sharpen edges? Because you have some prior knowledge that the world is composed of mostly smooth areas and sharp edges. That's prior knowledge. That's a buzzword. In artificial intelligence, if you have a large training set, you have more prior knowledge about the world. And these diffusion models have a lot of training data and therefore a lot of prior knowledge. So they'll look at every 10th pixel or every hundredth pixel in area and say, oh, that looks like a building. Buildings have windows. The windows have sharp edges. I will sharpen all that up and make it a stucco facade and then a dark window. And so they're clearly making stuff up. When you're using generative AI, I think all of the smartphone vendors will admit that they're making stuff up. The question is, is it useful? What are you doing with the image? And that determines whether it's okay to do that kind of stuff. One thing I will say more about Pixel is they do say they're not doing it for people. Correct. And that is an admission that it does matter what the Gen AI is used for. But again, back to the general argument, it's useful for some things and not useful or even misleading for other things. And so I think that'll be the discussion that everyone has going forward about the use of Gen AI and digital scaling: is what's it being used for? And does it work or does it make up stuff that's objectionable? Yeah, I think there's maybe a parallel to the moment we're in with AI generally. And my framework is what is the features on the phone mostly. And there's sort of a rush to have a bunch of AI stuff and sort of flashy, but not that useful. And I think, I hope we're getting to a place with it where we can think of it more as a tool that is just sort of there when we need it and is helpful. And then we don't think about it when we don't need it. It sounds like that's kind of what you're hinting at. Right. Let me make one further distinction. There's AI and there's Gen AI. Now, those terms are kind of fuzzy themselves. But when we think of text to image or text to video, everyone thinks of a certain kind of Gen AI. Let's use that definition. But AI is much more general than that. AI can just help you answer any question where you might benefit from prior knowledge. So the 10x multi-frame super resolution that Indigo has is using an AI. It's not using an AI to propose what the pixels ought to be, but to help align the multiple frames. The multiple frames all look a little bit different because when you hold your phone, you naturally shake a little bit. And so it gets different views of the world. And that actually provides additional real information about the scene. And the AI helps us align it and predict how we should weight those different images. So that's an AI. It's being used as a tool, but it's not Gen AI. So one more thing I'll say about that is: well, why can't you just keep doing that and take more and more frames and get 100x? And you can't. And the reason you can't is because there is a fundamental limit on how much detail gets through a lens. It's called the diffraction limit. And every lens has a diffraction limit. And for most smartphones, there might be 2x more information in each of horizontal and vertical than the pixels normally allow. There might not, depending on the lens, there isn't 10x more in each of x and y or each of horizontal and vertical. So at that point, you definitely are making stuff up. Yeah, right. That sort of relates to something I think about a lot with smartphone cameras is the role of hardware versus software. It kind of seems like, especially in the major players in the U.S., that we've sort of leveled out on the hardware. You know, we're not talking about a new bigger camera sensor every single year. You know, it's sort of like the same sensor with some tweaks to the software, which is not quite the case, I think. If you look outside the U.S., my colleague Dominic Presny gets to play with the, you know, the Xiaomi phones that come out, and they seem to be trying some really. Interesting stuff with the hardware, the really big one-inch type sensors. We're going back to attachments that you put on your smartphone that turn it into more of a camera. So I assume you realize that the major limitation there is the thickness of the phone. Yeah. That's what it's all about. The fundamental optics of a camera says that if you want a larger sensor, you've got to have more space between the lens and the sensor. And you can do quite a variety of hardware tricks to finesse that a little bit, but not a lot. And so basically a larger sensor means a thicker phone. And yeah, maybe our sensibilities are that we just don't want that and we're going to kind of settle on, you know, we get what we get. Do you think there is innovation to be had in the camera hardware? You know, it's within the bounds of what we'll tolerate as, you know, how thick a phone can be, how big a camera bump can be. So far, all that innovation has been incremental, but very useful. As a specific example, when I was working on Pixel, we used Sony sensors, and every year the Sony sensors would get better. Just a little bit better, but they really would get better. One of the ways they got better is that what's called the read noise, the extra random stuff that gets introduced when the pixels are read off of the sensor, would get less and less. And so in the last couple of years that I was at Google, we could do astrophotography where it's very, very dark, and you need that read noise to be small. We could successfully do it. Whereas a few years before, we really couldn't. And so these incremental improvements are useful. On the telephoto lenses, many of the smartphone vendors, including iPhone, have gone to what's called a periscope or a bended optics. Yeah. That's an interesting development. So there are hardware developments to be had. They're slow, they're incremental, but they're useful. Yeah. Okay. Well, that gives me hope. I don't know. There's something fun about new hardware as much as, you know, software is important on this subject of innovations and things coming up. I wonder if you can give us a taste of what you're working on next for Project Indigo. I know it's, would you call it a beta? It's in the Adobe Labs kind of under development state, if that's correct. Right. I wouldn't, the blog doesn't even characterize it as beta. It says experimental. Okay, yeah. Meaning this might or might not turn into a product for Adobe. Yeah. So in the blog, we talk about a few things. One of them is I would love to do exposure bracketing, where you, there are some scenes that are so high dynamic range that just underexposing and to reduce clipping of highlights and averaging of more frames to reduce noise in the shadows isn't enough. The example that we have in the blog is a moon over a moonlit landscape. So the full moon over a moonlit landscape, the difference in brightness between those two is 19 F-stops, meaning two to the 19th power, meaning about half a million to one. That's beyond the dynamic range of any camera, even an SLR. So if you wanted to capture a full moon and a moonlit landscape, you need to bracket. By bracketing, I mean capturing multiple images with different shutter speeds. And so, of course, SLRs let you do that. There's some of that in the smartphone industry. We would like to do a lot more of it in Indigo. Yeah. Another similar thing that is also mentioned in the blog is focus bracketing, meaning let's move the lens in between captures and then combine them to make what is called an all-in-focus image. So you would think, well, you know, in a smartphone, everything's in focus more or less. Well, that's true for things that are far away, but not for things that are close. So I don't know what your killer app for all-in-focus might be, but I know my killer app, it's food, my dinner at a nice restaurant where it's worth photographing. It's very hard to get the whole dinner plate in focus. Yeah. You can do it if you shoot from above looking down, but not if you shoot obliquely. Yeah. You're so close. And yeah, you're like, is the tomato on the top of the salad or the plate behind it going to be in focus? Yeah. So those are two things that are kind of obvious. There are a number of other things that we're exploring. They basically fall into the same camp of let's take a bit more time during capture, try a number of different things, combine them computationally. What I'd love to do, as the blog says, is to keep all the data, not just one image, so that you could also play with it later in an editor. Yeah. And that's a great example of where the camera app and the editing app can work in synergy. Yeah. A little bit of a nice advantage when you work for Adobe. Exactly. Okay, but I have to ask for my Android people. Is there an Android version come in? It's definitely on the want list. Okay. I used to work on building Android camera apps, of course, right at Google. As a matter of fact, the API, the application programming interface for the camera, was something that I and my graduate students at Stanford designed. The so-called Camera 2 programming interface for Android came out of a project at Stanford called the Franken Camera Project. Oh, nice. And it's a great interface, and I would love to address it. But Android has challenges. It's a very diverse and fragmented ecosystem. Not every vendor implements the Camera 2 API well. And we'll have to deal with all those challenges if we try to build an Android version of it. Yeah. Okay. That sort of comes to mind. If this is a universal camera app, like, well, I want it on my Android phones. Yeah. I guess I set myself up for this by calling it Universal five years ago, didn't I? You did do this to yourself. So well, it was deliberate. Yeah, yeah. Think big, you know. Well, I appreciate this so much. Thank you, Mark. And I know a ton of Verge readers are interested in your work and we're loving playing with Project Indigo. So they're going to be tuned in to what you're working on next. Good. And for all the Redditors out there who are one who are largely positive, which I'm relieved to see, Reddit is not always positive. Yeah. But the one complaint they have is, where are the updates? To them, I'll say they're coming. Okay. There you go. Well, thank you so much. It's been a pleasure talking to you, Allison. So we've got to take a quick break, and right after that, we'll be back with a hotline question. All right, we're back. We're going to take a hotline question now. And as always, the number for that is 866-VERGE11. And our email is vergecast at the verge.com. We love the questions, keep them coming, and we answer at least one on every show. So definitely write in or call in. This week's question comes from someone who isn't that concerned about image quality on their phone, but they're a little bit bothered by the camera bump. Hello, I am Oslogo. I'm calling to talk about cameras on phones. I, for one, don't care much about the quality of the camera, to be honest. And I think that if I want to get the best phone available on the market, I have to basically live with a bump that is almost to the size of the overall phone. So I just wonder about where are we going with this? Because it seems that these camera bumps just keep getting bigger and bigger. And somehow the phones get thinner on the other side, but then the size of the bump is not taking into account from the overall size of the phone when things get previewed and measured. So that seems pretty weird that let's say that the phone size is an overall five or whatever, and then the bump is a two on top of that, but then somehow it gets reported that the size of the phone is just a lower number. So I don't know. I just, I just wondering if there's like any hope out there for a top-of-the-line phone to just basically start moving away from the bump and then having the having be the case that we can have a phone that has the specs of a top of the line, but not the oversized phone that would allow us to at least have the phone sit like fresh on the table. So I guess, yes, just food for thought. Thank you. So I need to start with mostly bad news. Oswaldo, I am so sorry. I don't think the camera bumps are going away. But I love this question because, A, I appreciate the honesty, really don't care about the image quality, just tired of living with a big camera bump. And B, I think it's just saying out loud what a lot of us are thinking or bothered by. But I know I, for one, just want all the best image quality I can get. So it's sort of something I've shoved into the back of my head that I can live with. But I think there's a few reasons why the camera bump is not going away, especially on the pro in the higher-tier models that. Faldo's talking about. So these are the phones that tend to have the best camera, you know, the best of the best. And those cameras have bigger sensors. That is a huge benefit when you're taking pictures in low light or really any situation. But a bigger sensor means it needs a bigger lens, hence a big camera bump. So there's a little bit of a caveat to this that outside of the U.S., this is maybe even a worse problem where some of the Xiaomi's of the world are, you know, betting on really big image sensors and big lenses and just sort of going all the way into, you know, the heck with it. A camera bump is going to be huge and people will just live with that. So I think what we have to deal with here is maybe a little bit better. And I do think the point about phones getting thinner, but the camera bump kind of remaining a problem is legitimate. I tested the Galaxy S25 Edge, which is a super thin phone, but that camera bump is maybe as thick as the phone itself. And something that really bothered me when I tested it is putting it on the table, as Osfaldo mentioned, does not sit flush on a table and it wobbles like all heck when you tap on it. This is made worse by my habit of not putting cases on phones, which I think is one of the solutions here. So I don't think the camera bumps are going away. Putting a case on your phone, depending on the phone in the case, you know, you can shop around a little bit for something that sort of evens out the camera bump. I think a, you know, a pop socket or a case with a built-in stand could help if you're really bothered by setting your phone down and having it wobble on the tabletop. Those would be things to look at if you haven't already. There's maybe good news coming or bad. I can't really tell. The rumors of the iPhone, the impending iPhone 17, show like an elongated camera bump. That might help even out the wobble situation. I just tested the Pixel 10 Pro, and Pixel phones have that long, kind of elongated oval of a camera bump, and it's big and chunky for sure. But when you set it on a table, it's a little bit of a stable stand for the phone. So it props it up a little bit, doesn't wobble around. So there are trade-offs there. Perhaps the iPhone is moving to something similar. It's still a big camera bump. So I think you've got to look at a case that's maybe going to help. If all else fails, I find a drink coaster is my friend. I am always putting my phone on a drink coaster when I'm sitting at the table and I'm tired of it wobbling around. So we've always got that, Oswaldo. I'm sorry. I hope that helps, but maybe the help is in just saying it out loud and knowing that you're not suffering alone. So thanks for calling in. All right, that's it for The Verge Cast today. To read more about the topics we covered, check the show notes or head to theverge.com. And if you like what we do here, consider buying a paid subscription. The show is produced by Eric Gomez, Brennan Kiefer, Travis Larchuk, and Andrew Marino. The Vergecast is a Verge production and part of the Vox Media Podcast Network. Jake Astronakis and the team will be here Friday to talk about the news. Thanks for listening.